Automatically generated by Mendeley Desktop 1.17.9
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@techreport{EYeka2015,
author = {EYeka},
file = {:Users/AnneSofie/Downloads/eYeka{\_}AnalystReport{\_}CS{\_}report{\_}2015.pdf:pdf},
pages = {1--18},
title = {{The State of crowdsourcing 2015 - How the world's biggest brands and companies are opening up to consumer creativity}},
year = {2015}
}
@article{Difallah,
annote = {Looks at the evolution of a populair micro-task crowdsourcing platform 

HITs = Human Intelligence Tasks
Focus on paid micro-task crowdcourcing, the crowd is asked to perform short tasks, also known as HITs},
author = {Difallah, D. E. and Catasta, M. and Dermartini, G. and Ipeirotis, P. G. and Cudr{\'{e}}-Mauroux, P.},
file = {:Users/AnneSofie/Library/Application Support/Mendeley Desktop/Downloaded/Difallah et al. - Unknown - The Dynamics of Micro-Task Crowdsourcing.pdf:pdf},
journal = {2015},
title = {{The Dynamics of Micro-Task Crowdsourcing}},
url = {http://www.ipeirotis.com/wp-content/uploads/2015/02/frp1365-difallah.pdf}
}
@article{Sarasua2012,
abstract = {The last decade of research in ontology alignment has brought a va-riety of computational techniques to discover correspondences between ontolo-gies. While the accuracy of automatic approaches has continuously improved, human contributions remain a key ingredient of the process: this input serves as a valuable source of domain knowledge that is used to train the algorithms and to validate and augment automatically computed alignments. In this paper, we introduce CROWDMAP, a model to acquire such human contributions via micro-task crowdsourcing. For a given pair of ontologies, CROWDMAP translates the alignment problem into microtasks that address individual alignment questions, publishes the microtasks on an online labor market, and evaluates the quality of the results obtained from the crowd. We evaluated the current implementation of CROWDMAP in a series of experiments using ontologies and reference align-ments from the Ontology Alignment Evaluation Initiative and the crowdsourcing platform CrowdFlower. The experiments clearly demonstrated that the overall ap-proach is feasible, and can improve the accuracy of existing ontology alignment solutions in a fast, scalable, and cost-effective manner.},
annote = {introduce CROWDMAP an approach to integrate human and computational intelligence in ontology alignment tasks via microtask crowdsourcing},
author = {Sarasua, Cristina and Simperl, Elena and Noy, Natalya F},
file = {:Users/AnneSofie/Library/Application Support/Mendeley Desktop/Downloaded/Sarasua, Simperl, Noy - 2012 - LNCS 7649 - {\{}sc CrowdMap{\}} Crowdsourcing Ontology Alignment with Microtasks.pdf:pdf},
pages = {525--541},
title = {{Crowdsourcing Ontology Alignment with Microtasks}},
url = {http://download.springer.com/static/pdf/580/chp{\%}253A10.1007{\%}252F978-3-642-35176-1{\_}33.pdf?originUrl=http{\%}3A{\%}2F{\%}2Flink.springer.com{\%}2Fchapter{\%}2F10.1007{\%}2F978-3-642-35176-1{\_}33{\&}token2=exp=1493736116{~}acl={\%}2Fstatic{\%}2Fpdf{\%}2F580{\%}2Fchp{\%}25253A10.1007{\%}25252F978-3-64},
year = {2012}
}
@article{Leppink2014,
abstract = {In two studies, we investigated whether a recently developed psychometric instrument can differentiate intrinsic, extraneous, and germane cognitive load. Study I revealed a similar three-factor solution for language learning (n = 108) and a statistics lecture (n = 174), and statistics exam scores correlated negatively with the factors assumed to represent intrinsic and extraneous cognitive load during the lecture. In Study II, university freshmen who studied applications of Bayes' theorem in example–example (n = 18) or example–problem (n = 18) condition demonstrated better posttest performance than their peers who studied the applications in problem–example (n = 18) or problem–problem (n = 20) condition, and a slightly modified version of the aforementioned psychometric instrument could help researchers to differentiate intrinsic and extraneous cognitive load. The findings provide support for a recent reconceptualization of germane cognitive load as referring to the actual working memory resources devoted to dealing with intrinsic cognitive load.},
author = {Leppink, Jimmie and Paas, Fred and van Gog, Tamara and van der Vleuten, Cees P.M. and van Merri{\"{e}}nboer, Jeroen J.G.},
doi = {10.1016/j.learninstruc.2013.12.001},
file = {:Users/AnneSofie/Library/Application Support/Mendeley Desktop/Downloaded/Leppink et al. - 2014 - Effects of pairs of problems and examples on task performance and different types of cognitive load(3).pdf:pdf},
issn = {09594752},
journal = {Learning and Instruction},
pages = {32--42},
title = {{Effects of pairs of problems and examples on task performance and different types of cognitive load}},
url = {http://www.sciencedirect.com/science/article/pii/S0959475213000820},
volume = {30},
year = {2014}
}
@article{Saito2014,
abstract = {We propose a framework of micro-tasking that intrinsically supports the development of workers' skills. It aims to help developers of micro-tasking systems add skill development capabilities to their systems with minimal devel-opment costs. This will allow micro-tasking of skill-intensive work and im-prove the sustainability of micro-tasking systems. Based on the results of the micro-tasking projects we have carried out, our framework has three core mod-ules: tutorial producer, task dispatcher, and feedback visualizer, which are sup-ported by a back-end skill assessment engine. In closing, we discuss ways to apply the proposed framework to realistic micro-tasking situations.},
annote = {If micro-tasking systems support skill development, they can produce outcomes of higher-quality and make their use more sustainable. The skill de- velopment support will make micro-tasking more suitable for more advanced tasks that call for expert skills

Good figure of the micro-tasking platform workflow},
author = {Saito, Shin and Watanabe, Toshihiro and Kobayashi, Masatomo and Takagi, Hironobu},
file = {:Users/AnneSofie/Library/Application Support/Mendeley Desktop/Downloaded/Saito et al. - 2014 - Skill Development Framework for Micro-Tasking.pdf:pdf},
journal = {LNCS},
keywords = {Crowdsourcing,Gamification,Micro-Tasks,Senior Workforce,Skill Assessment,Skill Develop-ment},
pages = {400--409},
title = {{Skill Development Framework for Micro-Tasking}},
volume = {8514},
year = {2014}
}
@article{Kittur2008,
abstract = {User studies are important for many aspects of the design process and involve techniques ranging from informal surveys to rigorous laboratory studies. However, the costs involved in engaging users often requires practitioners to trade off between sample size, time requirements, and monetary costs. Micro-task markets, such as Amazon's Mechanical Turk, offer a potential paradigm for engaging a large number of users for low time and monetary costs. Here we investigate the utility of a micro-task market for collecting user measurements, and discuss design considerations for developing remote micro user evaluation tasks. Although micro-task markets have great potential for rapidly collecting user measurements at low costs, we found that special care is needed in formulating tasks in order to harness the capabilities of the approach.},
annote = {Although micro-task markets have great potential for rapidly collecting user measurements at low costs, we found that special care is needed in formulating tasks in order to harness the capabilities of the approach.},
author = {Kittur, Aniket and Chi, Ed H and Suh, Bongwon},
file = {:Users/AnneSofie/Library/Application Support/Mendeley Desktop/Downloaded/Kittur, Chi, Suh - Unknown - Crowdsourcing User Studies With Mechanical Turk.pdf:pdf},
keywords = {Author's kit,Conference Publications,Guides,instructions},
title = {{Crowdsourcing User Studies With Mechanical Turk}},
year = {2008}
}
@misc{Gee,
annote = {- You will often hear programmers talking about complexity reduction but actually what is going on is complexity hiding - also known in the wider world as "chunking". The idea behind chunking is that a human can deal with about seven things at a time. 
- The principle of chunking applied to programming is to build a hierarchy of code each composed of small objects that can be understood in a single look. 
- The point is that seven is a guideline and the actual number depends on all sort of factors but "Keep It Small Stupid" is a much better statement of intent than "Keep It Simple Stupid".
- The real confounding factor is what exactly constitutes an item that the "seven" applies to? Should it be seven characters, seven words, seven lines, seven subroutines, seven objects, seven programs....

The Unit Of Comprehension = grad av forst{\aa}else},
author = {Gee, Sue},
title = {{The Magic Number Seven And The Art Of Programming}},
url = {http://www.i-programmer.info/babbages-bag/621-the-magic-number-seven.html},
urldate = {2017-03-21}
}
@book{Ben2009,
author = {Ben, Schneiderman and Plaisant, Catherine},
edition = {Fifth},
isbn = {0-321-60148-3},
publisher = {Pearson},
title = {{Designing the User Interface}},
year = {2009}
}
@article{Gadiraju2015,
author = {Gadiraju, Ujwal and Demartini, Gianluca and Kawase, Ricardo and Dietze, Stefan},
doi = {10.1109/MIS.2015.66},
file = {:Users/AnneSofie/Documents/5.klasse/master/papers/opportunitiesofmicrotaskcrowdsourcing.pdf:pdf},
issn = {1541-1672},
journal = {IEEE Intelligent Systems},
month = {jul},
number = {4},
pages = {81--85},
title = {{Human Beyond the Machine: Challenges and Opportunities of Microtask Crowdsourcing}},
url = {http://ieeexplore.ieee.org/document/7156008/},
volume = {30},
year = {2015}
}
@article{Hecht2013,
abstract = {Due to financial or administrative constraints, access to official spatial base data is currently limited to a small subset of all potential users in the field of spatial planning and research. This increases the usefulness of Volunteered Geographic Information  (VGI), in particular OpenStreetMap (OSM), as supplementary datasets or, in some cases, alternative sources of primary data. In contrast to the OSM street network, which has already been thoroughly investigated and found to be practically complete in many areas, the degree of completeness of OSM data on buildings is still unclear. In this paper we describe methods to analyze building completeness and apply these to various test areas in Germany. Official data from national mapping and cadastral agencies is used as a basis for comparison. The results show that unit-based completeness measurements (e.g., total number or area of buildings) are highly sensitive to disparities in modeling between official data and VGI. Therefore, we recommend object-based methods to study the completeness of OSM building footprint data. An analysis from November 2011 in Germany indicated a completeness of 25{\%} in the federal states of North Rhine-Westphalia and 15{\%} in Saxony. Although further analyses from 2012 confirm that data completeness in Saxony has risen to 23{\%}, the rate of new data input was slowing in the year 2012.},
annote = {Due to financial or administrative constraints, access to official spatial base data is currently limited to a small subset of all potential users in the field of spatial planning and research. This increases the usefulness of Volunteered Geographic Information (VGI), in particular OpenStreetMap (OSM), as supplementary datasets or, in some cases, alternative sources of primary data. In contrast to the OSM street network, which has already been thoroughly investigated and found to be practically complete in many areas, the degree of completeness of OSM data on buildings is still unclear.},
author = {Hecht, Robert and Kunze, Carola and Hahmann, Stefan},
doi = {10.3390/ijgi2041066},
file = {:Users/AnneSofie/Library/Application Support/Mendeley Desktop/Downloaded/Hecht, Kunze, Hahmann - 2013 - Measuring Completeness of Building Footprints in OpenStreetMap over Space and Time.pdf:pdf},
issn = {2220-9964},
journal = {ISPRS International Journal of Geo-Information},
keywords = {OpenStreetMap,Volunteered Geographic Information (VGI),building data,completeness,quantitative comparison},
month = {nov},
number = {4},
pages = {1066--1091},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{Measuring Completeness of Building Footprints in OpenStreetMap over Space and Time}},
url = {http://www.mdpi.com/2220-9964/2/4/1066/},
volume = {2},
year = {2013}
}
@article{Deng2016,
abstract = {Advancements in Internet and digital technologies have enabled a new work form of open sourcing, which we refer to as the crowdsourcing work environment (CSWE). This new form of work has the potential to disrupt and transform the nature of traditional work. However, our understanding of this new work form is still in its incipient stage. To enhance our understanding, this study captures crowdworkers' perceptions to explore the characteristics of the crowdworkers, crowdsourcing jobs, and the crowdwork environment that collectively drive the crowdworkers to participate in open source work. Guided by the job characteristic theory and work value perspectives, we used the revealed causal mapping method to analyze narratives by 55 crowdworkers registered on Amazon Mechanical Turk (MTurk). Our data analysis uncovered nine main constructs, 22 key concepts, and 815 causal-effect linkages surrounding CSWE that could guide our theoretical understanding of this emerging phenomenon. Individual needs and the crowdwork context emerged as the major factors motivating individuals' initial participation in CSWE, but we found crowdsourcing task characteristics (e.g., job autonomy, task variety, task significance, task instruction, and task compensation) and a digitally enabled environment (e.g., system affordance and MTurk governance) to shape crowdworkers' continued participation in CSWE. The findings suggest several promising research streams, including the psychological factors (i.e., personal growth needs and work values) and social outcomes (i.e., empowerment or exploitation of crowdworkers) for examining the psychology and sociology of crowdsourcing work.},
annote = {Focuses on the micro-task CSWE (CSWE = crowdsourcing work environment). 

Worried - micro-task workers get poorly paid

Try to answer following: 
Q1 - Why do individuals participate in micro-task CSWE?
Q2 - Their characteristics, and what drives them

Focus on MTurk},
author = {Deng, Xuefei and Joshi, K D},
file = {:Users/AnneSofie/Library/Application Support/Mendeley Desktop/Downloaded/Deng, Joshi - 2016 - Why Individuals Participate in Micro-task Crowdsourcing Work Environment Revealing Crowdworkers' Perceptions.pdf:pdf},
number = {10},
pages = {648--673},
title = {{Why Individuals Participate in Micro-task Crowdsourcing Work Environment: Revealing Crowdworkers' Perceptions}},
volume = {17},
year = {2016}
}
@article{Difallah2016,
address = {New York, New York, USA},
annote = {With increasedmomentum around crowdsourcing for both academic and commercial purposes [12], managing the efficiency of a crowdsourcing platform in delivering results and completing tasks becomes a challenge.

Individual workers perform slightly better when work- ing on homogeneous batches (compared to batches re-Individual workers perform slightly better when work- ing on homogeneous batches (compared to batches re-grouping different types of HITs);

Studies in the psychology domain have shown that switching between different tasks types has a negative effect on worker reaction time and on the quality of the work done

human individuals behave very differently from machines, they are sen- sitive to the context switch that a regular scheduler might cause.},
author = {Difallah, Djellel Eddine and Demartini, Gianluca and Cudr{\'{e}}-Mauroux, Philippe},
doi = {10.1145/2872427.2883030},
file = {:Users/AnneSofie/Library/Application Support/Mendeley Desktop/Downloaded/Difallah, Demartini, Cudr{\'{e}}-Mauroux - 2016 - Scheduling Human Intelligence Tasks in Multi-Tenant Crowd-Powered Systems.pdf:pdf},
isbn = {9781450341431},
journal = {Proceedings of the 25th International Conference on World Wide Web  - WWW '16},
pages = {855--865},
publisher = {ACM Press},
title = {{Scheduling Human Intelligence Tasks in Multi-Tenant Crowd-Powered Systems}},
url = {http://dl.acm.org/citation.cfm?doid=2872427.2883030},
year = {2016}
}
@article{Mcandrew2016,
annote = {OSM database schema - apidb.

OSMOSIS tool - perform data management tasks

pg{\_}snapshot - database schema},
author = {Mcandrew, James},
file = {:Users/AnneSofie/Library/Application Support/Mendeley Desktop/Downloaded/Mcandrew - 2016 - Digital Commons @ DU Merging Volunteered Geographic Information Systems.pdf:pdf},
title = {{Digital Commons @ DU Merging Volunteered Geographic Information Systems}},
url = {http://digitalcommons.du.edu/geog{\_}ms{\_}capstone http://digitalcommons.du.edu/geog{\_}ms{\_}capstone/54},
year = {2016}
}
@article{Deng2016a,
annote = {Crowdsourcing (CS) - It radically changes the nature of work: rather than being confined to offices and stipulated office hours, people can conduct work at home, choose when to work, and decide which jobs to perform. CS, thus, appears very attractive—on the surface, that is.

The demand for microtask CS is one of the most rapidly expanding trends (Bratvold 2011).

Academic work includes Deng and Joshi (2013), who explored crowd workers' perceptions of microtask CS as a career choice, finding that work flexibility and work autonomy were the two major positive aspects.

Individuals who perform micro tasks for micropayment as crowd workers

Microtask CS is a complex online labor marketplace phenomenon that involves multiple stakeholders, thus requiring consideration of multiple user perspectives in CS platform design.},
author = {Deng, Xuefei and Joshi, K D and Galliers, Robert D},
file = {:Users/AnneSofie/Library/Application Support/Mendeley Desktop/Downloaded/Deng, Joshi, Galliers - 2016 - THE DUALITY OF EMPOWERMENT AND MARGINALIZATION IN MICROTASK CROWDSOURCING GIVING VOICE TO THE LESS POWERF.pdf:pdf},
number = {2},
pages = {279--300},
title = {{THE DUALITY OF EMPOWERMENT AND MARGINALIZATION IN MICROTASK CROWDSOURCING: GIVING VOICE TO THE LESS POWERFUL THROUGH VALUE SENSITIVE DESIGN 1}},
url = {http://aisel.aisnet.org/cgi/viewcontent.cgi?article=3283{\&}context=misq},
volume = {40},
year = {2016}
}
@article{Tong,
abstract = {—With the rapid development of smartphones, spatial crowdsourcing platforms are getting popular. A foundational research of spatial crowdsourcing is to allocate micro-tasks to suitable crowd workers. Most existing studies focus on offline scenarios, where all the spatiotemporal information of micro-tasks and crowd workers is given. However, they are impractical since micro-tasks and crowd workers in real applications appear dynamically and their spatiotemporal information cannot be known in advance. In this paper, to address the shortcomings of existing offline approaches, we first identify a more practical micro-task allocation problem, called the Global Online Micro-task Allocation in spatial crowdsourcing (GOM A) problem. We first extend the state-of-art algorithm for the online maximum weighted bipartite matching problem to the GOMA problem as the baseline algorithm. Although the baseline algorithm provides theoretical guarantee for the worst case, its average performance in practice is not good enough since the worst case happens with a very low probability in real world. Thus, we consider the average performance of online algorithms, a.k.a online random order model. We propose a two-phase-based framework, based on which we present the TGOA algorithm with 1 4 -competitive ratio under the online random order model. To improve its efficiency, we further design the TGOA-Greedy algorithm following the framework, which runs faster than the TGOA algorithm but has lower competitive ratio of 1 8 . Finally, we verify the effective-ness and efficiency of the proposed methods through extensive experiments on real and synthetic datasets.},
annote = {how to allocate the tasks to suitable workers in real-time dynamic environments (a.k.a online scenarios) and model such online scenarios?

The worker can only conduct tasks that locate within the range, which is shown as a dotted circle in Fig. 1.},
author = {Tong, Yongxin and She, Jieying and Ding, Bolin and Wang, Libin and Chen, Lei},
file = {:Users/AnneSofie/Library/Application Support/Mendeley Desktop/Downloaded/Tong et al. - Unknown - Online Mobile Micro-Task Allocation in Spatial Crowdsourcing.pdf:pdf},
title = {{Online Mobile Micro-Task Allocation in Spatial Crowdsourcing}}
}
